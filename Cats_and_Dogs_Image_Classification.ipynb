{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaythakur3369/Prodigy-InfoTech-Internship/blob/main/Cats_and_Dogs_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dF6hEQkAdIb"
      },
      "source": [
        "# **Project Name - Cats and Dogs Image Classification**\n",
        "## **Developed By - Ajay Thakur (ajaythakur3369@gmail.com)**\n",
        "## **Branch Name - Electronics and Communication Engineering**\n",
        "## **Institute Name - Indian Institute of Information Technology Kota**\n",
        "## **Submitted To - Prodigy InfoTech**\n",
        "## **Project Link (GitHub) - [Click here](https://github.com/ajaythakur3369/Prodigy-InfoTech-Internship)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmgU1YfPAeNh"
      },
      "source": [
        "# **Problem Statement -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5RQuFu6BAtr"
      },
      "source": [
        "Implementing a support vector machine (SVM) to classify images of cats and dogs from the Kaggle dataset.\n",
        "\n",
        "\n",
        "**Dataset -** https://www.kaggle.com/c/dogs-vs-cats/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a97LgwfXunrv"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onubj2T0rydL",
        "outputId": "753a048f-aafa-4c6a-8273-0428fb5ead5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Access the Drive from Colab to retrieve the file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YmyCTY9rC6Y"
      },
      "outputs": [],
      "source": [
        "# Path for accessing all the required files from Drive\n",
        "Cats_and_Dogs_data = '/content/drive/MyDrive/Colab_Notebook/Internship_Name/Prodigy_InfoTech/Folder_Name/Cats_and_Dogs_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPuNS1aW9nCl",
        "outputId": "5d7c85aa-c639-4c56-8d0e-1c650ef832cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25089 files belonging to 1 classes.\n",
            "Found 12571 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# Generators\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/drive/MyDrive/Colab_Notebook/Internship_Name/Prodigy_InfoTech/Folder_Name/Cats_and_Dogs_dataset/Dogs_dataset',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size = 32,\n",
        "    image_size = (256, 256)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/drive/MyDrive/Colab_Notebook/Internship_Name/Prodigy_InfoTech/Folder_Name/Cats_and_Dogs_dataset/Cats_dataset',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size = 32,\n",
        "    image_size = (256, 256)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aoSxYDI9qJ3"
      },
      "outputs": [],
      "source": [
        "# Normalize\n",
        "def process(image, label):\n",
        "    image = tf.cast(image/255. ,tf.float32)\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ym59KCJ9uNm"
      },
      "outputs": [],
      "source": [
        "# Create a CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,kernel_size = (3, 3), padding = 'valid', activation = 'relu', input_shape = (256, 256, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size = (3, 3), padding = 'valid', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size = (3, 3), padding = 'valid', activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Dense(1, kernel_regularizer = tf.keras.regularizers.l2(0.01), activation\n",
        "             ='linear'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eHn9z8o9wyG",
        "outputId": "1cb060b4-8ec4-4f5e-92e6-1707828494dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 254, 254, 32)      128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 125, 125, 64)      256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 60, 60, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30, 30, 1)         129       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 900)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               115328    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 217922 (851.26 KB)\n",
            "Trainable params: 217474 (849.51 KB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35QeBFz79y-K"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyHVZ9c0Gg3l",
        "outputId": "4e3ab839-2434-450b-c893-92f1af0a8193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "330/785 [===========>..................] - ETA: 53:01 - loss: 0.0180 - accuracy: 0.9980"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds, epochs = 2, batch_size = 64, verbose = 1, validation_data = validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q_MqYi8rGvjI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'], color = 'red', label = 'train')\n",
        "plt.plot(history.history['val_accuracy'], color = 'blue', label = 'validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_KfBv7MKrXBc"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], color = 'red', label = 'train')\n",
        "plt.plot(history.history['val_accuracy'], color = 'blue', label = 'validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7GlSvV-qrbT6"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], color = 'red', label = 'train')\n",
        "plt.plot(history.history['val_loss'], color = 'blue', label = 'validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qSrtikFarcvP"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], color = 'red', label = 'train')\n",
        "plt.plot(history.history['val_loss'], color = 'blue', label = 'validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Neypzm0crfM_"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LCByL4K_H9zC"
      },
      "outputs": [],
      "source": [
        "test_img = cv2.imread('/content/drive/MyDrive/Colab_Notebook/Internship_Name/Prodigy_InfoTech/Folder_Name/Cats_and_Dogs_dataset/Cats_dataset/Cats_images/12500.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PKSihG9BKQjd"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PePnJy7RsflB"
      },
      "outputs": [],
      "source": [
        "test_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7ywzVExxshJ_"
      },
      "outputs": [],
      "source": [
        "test_img = cv2.resize(test_img, (256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YKW5ubsqsjaL"
      },
      "outputs": [],
      "source": [
        "test_input = test_img.reshape((1, 256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qknWD5TwslWf"
      },
      "outputs": [],
      "source": [
        "model.predict(test_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TycW7t7Fsys3"
      },
      "outputs": [],
      "source": [
        "test_img2 = cv2.imread('/content/drive/MyDrive/Colab_Notebook/Internship_Name/Prodigy_InfoTech/Folder_Name/Cats_and_Dogs_dataset/Dogs_dataset/Dogs_images/dog.12499.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C3L14HNGs0Zz"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_img2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aUm27_tks5JC"
      },
      "outputs": [],
      "source": [
        "test_img2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oHuMc9ags5zY"
      },
      "outputs": [],
      "source": [
        "test_img2 = cv2.resize(test_img2, (256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jG9cvKtBs87p"
      },
      "outputs": [],
      "source": [
        "test_input2 = test_img2.reshape((1, 256, 256, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6ie5-9d3s-1d"
      },
      "outputs": [],
      "source": [
        "model.predict(test_input2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}